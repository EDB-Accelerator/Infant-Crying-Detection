{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from os.path import expanduser\n", "import glob\n", "import re\n", "import pandas as pd\n", "import os\n", "import sys"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Append a directory to the system path for importing custom modules"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sys.path.append('./src')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Import training functions from custom modules"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from train_alex import train_alex\n", "from train_svm import train_svm"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Download sample dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tarfile\n", "import os\n", "import subprocess\n", "extract_path = \"data\"\n", "tar_file = \"data.tar\"\n", "def downloadFileFromWeb(extract_path,tar_fil,url):\n", "    # Ensure the directory exists and is empty\n", "    os.makedirs(extract_path, exist_ok=True)\n\n", "    # Check if the folder is empty and proceed\n", "    if not os.listdir(extract_path):\n", "        # Download the file using wget\n", "        subprocess.run([\"wget\", \"-O\", tar_file, url], check=True)\n\n", "        # Extract the tar file\n", "        with tarfile.open(tar_file, \"r\") as tar:\n", "            tar.extractall(path=\".\")  # Extract all maintains original structure\n", "        print(f\"File downloaded and extracted to {extract_path}\")\n", "        os.remove(tar_file)\n", "    else:\n", "        print(f\"The folder '{extract_path}' is not empty. Extraction skipped.\")\n", "downloadFileFromWeb(\"data\",\"data.tar\",\"https://umd.box.com/shared/static/y5kbzxo827y4ohaq7rwzgzm25g7vkb1l.tar\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Download pretrained dataset (Please change this if you trained the model.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["downloadFileFromWeb(\".pretrained\",\"pretrained.tar\",\"https://umd.box.com/shared/static/qseveraeze15vbxztmq1aozbemil6yy9.tar\")\n", "alex_model_path = \".pretrained/alex_pretrained.h5\"\n", "svm_model_path = \".pretrained/svm_pretrained.joblib\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Gather all test files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_annotation_files = glob.glob(f\"./data/test/*.csv\")\n", "test_audio_files = glob.glob(f\"./data/test/*.wav\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sort files for consistent processing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_annotation_files.sort()\n", "test_audio_files.sort()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Preprocessing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from preprocessing import preprocessing\n", "os.makedirs(\"preprocessed\", exist_ok=True) # Ensure the directory exists and is empty\n", "test_preprocessed_files = []\n", "for i in range(len(test_audio_files)):\n", "    test_audio_file = test_audio_files[i]\n", "    test_annotation_file = test_annotation_files[i]\n", "    id = test_annotation_file.split('/')[-1].split('.csv')[0]\n", "    file_path = './preprocessed/{id}.csv'\n", "    test_preprocessed_files.append(file_path)\n", "    preprocessing(test_audio_file,file_path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Prediction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from predict import predict_alex_svm\n", "os.makedirs(\"prediction\", exist_ok=True) # Ensure the directory exists and is empty\n", "test_prediction_files = []\n", "for i in range(len(test_audio_files)):\n", "    test_audio_file = test_audio_files[i]\n", "    test_annotation_file = test_annotation_files[i]\n", "    id = test_annotation_file.split('/')[-1].split('.csv')[0]\n", "    file_path = f'./prediction/{id}.csv'\n", "    test_prediction_files.append(file_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["params = {\n", "    \"n_fft\": 980,\n", "    \"hop_length\": 490,\n", "    \"n_mels\": 225,\n", "    \"img_rows\": 225,\n", "    \"img_cols\": 225,\n", "    \"batch_size\": 128,\n", "    \"num_classes\": 2\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predictions,decision_scores = predict_alex_svm(params,test_audio_files,test_preprocessed_files,test_prediction_files,alex_model_path,svm_model_path,'torch',decision_scores_only=False,best_threshold=None)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}